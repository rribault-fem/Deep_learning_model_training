{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial\n",
    "This tutorial explains how to :\n",
    "- Prepare experiments for two models with different scalers and set up an experiments\n",
    "- Train the model\n",
    "- Compare model results thanks to tensorboard\n",
    "- Generate validation data and perform unscaling process."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review of two convolutional network\n",
    "First go to src\\model\\components\\conv1d_surr.py and read the model component definition.\n",
    "\n",
    "Then you can compare the conv1d_surr model with the conv1d_surr_nopca one.\n",
    "for conv1d_surr_nopca no PCA is shall be used during pre-processing. src\\model\\components\\conv1d_surr_nopca.py\n",
    "\n",
    "Open now the files configs\\model_net\\conv1d_surr_nopca.yaml and configs\\model_net\\conv1d_surr.yaml.\n",
    "\n",
    "User parameters to instanciate the models are defined inside them."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new experiment files\n",
    "Run the code below to create two new experiment files.\n",
    "When running an experiment with train.py, you run the defaults parameters defined in the train.yaml file but you overide parameters specified in the experiment file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from yaml import CLoader as Loader\n",
    "\n",
    "# create a dictionary with the parameters\n",
    "header = '# @package _global_'\n",
    "Document = \"\"\"\n",
    "defaults:\n",
    "   - override /model_net: conv1d_surr.yaml\n",
    "task_name: \"tutorial\"\n",
    "preprocessing:\n",
    "   perform_decomp : True\n",
    "   \n",
    "tags: [\"surrogate\", \"conv1d\", \"PCA\"]\n",
    "\"\"\"\n",
    "\n",
    "# The above experiment will use the 'conv1d_surr' model.\n",
    "# It will outputs the results in the folder 'outputs\\tutorial'.\n",
    "# The default decomposition which is a PCA will be performed during pre-processing.\n",
    "# The experiments tags, accessible in Tensorboard visualisation will be \"surrogate\", \"conv1d\", \"PCA\"\n",
    "\n",
    "yaml_doc = yaml.load(Document, Loader=Loader)\n",
    "\n",
    "# write the dictionary to a yaml file\n",
    "with open('../configs/experiment/tuto_conv_pca.yaml', 'w') as f:\n",
    "    f.write(header+'\\n')\n",
    "    yaml.dump(yaml_doc, f, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../configs/experiment/tuto_conv_nopca.yaml', 'w') as f :\n",
    "    Document = \"\"\"\n",
    "    defaults:\n",
    "        - override /model_net: conv1d_surr_nopca.yaml\n",
    "    task_name: \"tutorial\"\n",
    "    preprocessing:\n",
    "        perform_decomp : False\n",
    "    tags: [\"surrogate\", \"conv1d\", \"NoPCA\"]\n",
    "    \"\"\"\n",
    "    yaml_doc = yaml.load(Document, Loader=Loader)\n",
    "    f.write(header+'\\n')\n",
    "    yaml.dump(yaml_doc, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train both models\n",
    "Now train the 2x models with and without PCA by running train.py script.\n",
    "\n",
    "First set up the subprocess call for a jupyter notebook to emulate a terminal call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING : run this only one time, otherwise the current directory may be wrong\n",
    "\n",
    "# Change of working directory to the root of the project\n",
    "import os\n",
    "os.chdir('..')\n",
    "\n",
    "import subprocess\n",
    "\n",
    "def notebook_subprocess(command) :\n",
    "    # Execute the command within a subprocess\n",
    "    process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, universal_newlines=True)\n",
    "\n",
    "    # Read and print the output dynamically\n",
    "    for line in process.stdout:\n",
    "        print(line, end='')\n",
    "\n",
    "    # Wait for the process to finish\n",
    "    process.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\romain.ribault\\Anaconda3\\envs\\dmltp\\lib\\site-packages\\pkg_resources\\__init__.py:122: PkgResourcesDeprecationWarning: -0.1.0- is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "c:\\Users\\romain.ribault\\Anaconda3\\envs\\dmltp\\lib\\site-packages\\pkg_resources\\__init__.py:122: PkgResourcesDeprecationWarning: -0.1.0- is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "[2023-05-16 09:19:40,033][tutorial][INFO] - Instantiating Preprocessing <Preprocessing.Preprocessing>\n",
      "[2023-05-16 09:19:43,454][tutorial][INFO] -  run <get_cos_sin_decomposition> method\n",
      "[2023-05-16 09:19:43,454][tutorial][INFO] - ###\n",
      "[2023-05-16 09:19:43,454][tutorial][INFO] - get cos and sin decomposition of the data {'mag10': 'theta10', 'hs': 'dp'}\n",
      "[2023-05-16 09:19:43,455][tutorial][INFO] - get cos and sin decomposition of the data mag10 and theta10\n",
      "[2023-05-16 09:19:43,460][tutorial][INFO] - get cos and sin decomposition of the data hs and dp\n",
      "[2023-05-16 09:19:43,471][tutorial][INFO] - ###\n",
      "[2023-05-16 09:19:43,471][tutorial][INFO] - Splitting data into training and test sets with method <find_test_set_in_model_validity_domain>\n",
      "[2023-05-16 09:19:43,472][tutorial][INFO] - #####\n",
      "[2023-05-16 09:19:43,472][tutorial][INFO] - start guessing valid training / test set with the following environmental bin :\n",
      "[2023-05-16 09:19:43,472][tutorial][INFO] - {'hs': 2, 'tp': 2, 'dp': 45, 'mag10': 2, 'theta10': 45}\n",
      "[2023-05-16 09:19:43,472][tutorial][INFO] - looking for 60 test samples in training set, divided in 3 clusters \n"
     ]
    }
   ],
   "source": [
    "# run the model with PCA\n",
    "command = [\"python\", \"src/train.py\", \"experiment=tuto_conv_pca.yaml\" ]\n",
    "notebook_subprocess(command)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the logs in the jupyternotebook above.\n",
    "Full hydra output files are copied in a new folder of outputs\\tutorial\\runs.    \n",
    "Note that you defined the tutorial folder by specifying the task_name: \"tutorial\" in the experiment yaml file.    \n",
    "\n",
    "**You can order your experiments by task_name and model type to compare the models with tensorboard more easily.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the model without PCA\n",
    "command = [\"python\", \"src/train.py\", \"experiment=tuto_conv_nopca.yaml\" ]\n",
    "notebook_subprocess(command)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare models with tensorboard\n",
    "\n",
    "When training is over, you can see the results in tensorboard by running the code below in the root directory of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.11.0 at http://localhost:6006/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "# run tensorboard\n",
    "import subprocess\n",
    "command = [\"tensorboard\", \"--logdir\", r\"outputs/tutorial/runs\" ]\n",
    "process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, universal_newlines=True)\n",
    "for line in process.stdout:\n",
    "        print(line, end='')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open a browser and go to :\n",
    "http://localhost:6006/\n",
    "\n",
    "Now open the time series tab and compare the results of the two models.  \n",
    "open the train card to see the training results and the validation card to see the validation results.  \n",
    "Now open the HPARAMS tab and compare the hyperparameters of the two models.  \n",
    "\n",
    "Scroll down the hyperparameters and activate tags and hp_metric.\n",
    "Now you can identify which model use a PCA and compare the metrics of both models."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform inference and unscaling\n",
    "Now we will generate validation data and perform unscaling process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-15_13-34-48\n",
      "2023-05-15_11-38-05\n"
     ]
    }
   ],
   "source": [
    "# Specify the folder path\n",
    "folder_path =  r\"outputs/tutorial/runs\"\n",
    "\n",
    "# Get a list of all items (files and folders) within the folder\n",
    "items = os.listdir(folder_path)\n",
    "\n",
    "# Filter out the folders\n",
    "folders = [item for item in items if os.path.isdir(os.path.join(folder_path, item))]\n",
    "\n",
    "# Sort the folders by creation time (most recent first)\n",
    "sorted_folders = sorted(folders, key=lambda x: os.path.getctime(os.path.join(folder_path, x)), reverse=True)\n",
    "\n",
    "# Get the last two folders\n",
    "last_two_folders = sorted_folders[:2]\n",
    "\n",
    "# Print the last two folders\n",
    "for folder in last_two_folders:\n",
    "    print(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\romain.ribault\\Anaconda3\\envs\\dmltp\\lib\\site-packages\\pkg_resources\\__init__.py:122: PkgResourcesDeprecationWarning: -0.1.0- is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "c:\\Users\\romain.ribault\\Anaconda3\\envs\\dmltp\\lib\\site-packages\\pkg_resources\\__init__.py:122: PkgResourcesDeprecationWarning: -0.1.0- is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "[2023-05-16 09:53:13,848][utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>\n",
      "[2023-05-16 09:53:13,857][utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>\n",
      "[2023-05-16 09:53:13,857][utils.rich_utils][WARNING] - Field 'data' not found in config. Skipping 'data' config printing...\n",
      "[2023-05-16 09:53:13,857][utils.rich_utils][WARNING] - Field 'model' not found in config. Skipping 'model' config printing...\n",
      "[2023-05-16 09:53:13,858][utils.rich_utils][WARNING] - Field 'callbacks' not found in config. Skipping 'callbacks' config printing...\n",
      "[2023-05-16 09:53:13,859][utils.rich_utils][WARNING] - Field 'logger' not found in config. Skipping 'logger' config printing...\n",
      "[2023-05-16 09:53:13,859][utils.rich_utils][WARNING] - Field 'trainer' not found in config. Skipping 'trainer' config printing...\n",
      "CONFIG\n",
      "├── paths\n",
      "│   └── root_dir: C:\\Users\\romain.ribault\\Documents\\GitHub\\torchydra           \n",
      "│       data_dir: C:\\Users\\romain.ribault\\Documents\\GitHub\\torchydra/data/     \n",
      "│       log_dir: C:\\Users\\romain.ribault\\Documents\\GitHub\\torchydra/outputs/   \n",
      "│       output_dir: c:\\Users\\romain.ribault\\Documents\\GitHub\\torchydra\\outputs\\\n",
      "│       work_dir: c:\\Users\\romain.ribault\\Documents\\GitHub\\torchydra           \n",
      "│       dataset: C:\\Users\\romain.ribault\\Documents\\GitHub\\torchydra/data//netcd\n",
      "│       training_env_dataset: c:\\Users\\romain.ribault\\Documents\\GitHub\\torchydr\n",
      "│                                                                              \n",
      "├── extras\n",
      "│   └── ignore_warnings: false                                                 \n",
      "│       enforce_tags: true                                                     \n",
      "│       print_config: true                                                     \n",
      "│                                                                              \n",
      "├── task_name\n",
      "│   └── eval                                                                   \n",
      "├── tags\n",
      "│   └── ['dev']                                                                \n",
      "├── experiment_folder\n",
      "│   └── outputs/tutorial/runs/2023-05-15_13-34-48                              \n",
      "├── save_path\n",
      "│   └── \\\\10.12.89.104\\zefyros_calc\\PreProd\\storage                            \n",
      "└── date\n",
      "    └── 2022-12-02                                                             \n",
      "c:\\Users\\romain.ribault\\Anaconda3\\envs\\dmltp\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator MinMaxScaler from version 1.2.2 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\romain.ribault\\Anaconda3\\envs\\dmltp\\lib\\site-packages\\torchinfo\\torchinfo.py:477: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  action_fn=lambda data: sys.getsizeof(data.storage()),\n",
      "c:\\Users\\romain.ribault\\Anaconda3\\envs\\dmltp\\lib\\site-packages\\torch\\storage.py:665: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return super().__sizeof__() + self.nbytes()\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "conv1d_surr_nopca                        [1, 512, 18]              --\n",
      "├─Linear: 1-1                            [64]                      512\n",
      "├─ReLU: 1-2                              [64]                      --\n",
      "├─Linear: 1-3                            [32]                      2,080\n",
      "├─ReLU: 1-4                              [32]                      --\n",
      "├─Linear: 1-5                            [16]                      528\n",
      "├─ReLU: 1-6                              [16]                      --\n",
      "├─ConvTranspose1d: 1-7                   [1, 32, 32]               16,416\n",
      "├─ReLU: 1-8                              [1, 32, 32]               --\n",
      "├─ConvTranspose1d: 1-9                   [1, 64, 64]               4,160\n",
      "├─ReLU: 1-10                             [1, 64, 64]               --\n",
      "├─ConvTranspose1d: 1-11                  [1, 128, 128]             16,512\n",
      "├─ReLU: 1-12                             [1, 128, 128]             --\n",
      "├─ConvTranspose1d: 1-13                  [1, 256, 256]             65,792\n",
      "├─ReLU: 1-14                             [1, 256, 256]             --\n",
      "├─ConvTranspose1d: 1-15                  [1, 18, 512]              9,234\n",
      "├─ReLU: 1-16                             [1, 18, 512]              --\n",
      "==========================================================================================\n",
      "Total params: 115,234\n",
      "Trainable params: 115,234\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 24.58\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.77\n",
      "Params size (MB): 0.46\n",
      "Estimated Total Size (MB): 1.23\n",
      "==========================================================================================\n",
      "c:\\Users\\romain.ribault\\Anaconda3\\envs\\dmltp\\lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:197: UserWarning: Attribute 'net' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['net'])`.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\romain.ribault\\Anaconda3\\envs\\dmltp\\lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:197: UserWarning: Attribute 'criterion' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['criterion'])`.\n",
      "  rank_zero_warn(\n",
      "[2023-05-16 09:53:19,943][eval][INFO] - ###\n",
      "[2023-05-16 09:53:19,944][eval][INFO] - get cos and sin decomposition of the data {'mag10': 'theta10', 'hs': 'dp'}\n",
      "[2023-05-16 09:53:19,944][eval][INFO] - get cos and sin decomposition of the data mag10 and theta10\n",
      "[2023-05-16 09:53:19,955][eval][INFO] - get cos and sin decomposition of the data hs and dp\n",
      "[2023-05-16 09:53:19,962][eval][INFO] - # input_envir_set shape is (24, 7)\n",
      "[2023-05-16 09:53:19,963][eval][INFO] - Perform model predictions\n",
      "[2023-05-16 09:53:20,005][eval][INFO] - uncertainty propagation and calculate 95% confidence interval based on input uncertainties\n",
      "[2023-05-16 09:53:23,111][eval][INFO] - Save netcdf file\n",
      "[2023-05-16 09:53:25,462][eval][INFO] - file saved in \\\\10.12.89.104\\zefyros_calc\\PreProd\\storage/2022/12/02/ANN/surrogate_2023-05-15_13-34-48 \n",
      "[2023-05-16 09:53:25,473][utils.utils][INFO] - Output dir: c:\\Users\\romain.ribault\\Documents\\GitHub\\torchydra\\outputs\\eval\\runs\\2023-05-16_09-53-13\n"
     ]
    }
   ],
   "source": [
    "# Run first model trained\n",
    "command = [\"python\", \"src/surrogate_inference.py\", f\"experiment_folder=outputs/tutorial/runs/{last_two_folders[0]}\" ]\n",
    "notebook_subprocess(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\romain.ribault\\Anaconda3\\envs\\dmltp\\lib\\site-packages\\pkg_resources\\__init__.py:122: PkgResourcesDeprecationWarning: -0.1.0- is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "c:\\Users\\romain.ribault\\Anaconda3\\envs\\dmltp\\lib\\site-packages\\pkg_resources\\__init__.py:122: PkgResourcesDeprecationWarning: -0.1.0- is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "[2023-05-16 09:54:55,176][utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>\n",
      "[2023-05-16 09:54:55,185][utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>\n",
      "[2023-05-16 09:54:55,185][utils.rich_utils][WARNING] - Field 'data' not found in config. Skipping 'data' config printing...\n",
      "[2023-05-16 09:54:55,185][utils.rich_utils][WARNING] - Field 'model' not found in config. Skipping 'model' config printing...\n",
      "[2023-05-16 09:54:55,185][utils.rich_utils][WARNING] - Field 'callbacks' not found in config. Skipping 'callbacks' config printing...\n",
      "[2023-05-16 09:54:55,186][utils.rich_utils][WARNING] - Field 'logger' not found in config. Skipping 'logger' config printing...\n",
      "[2023-05-16 09:54:55,186][utils.rich_utils][WARNING] - Field 'trainer' not found in config. Skipping 'trainer' config printing...\n",
      "CONFIG\n",
      "├── paths\n",
      "│   └── root_dir: C:\\Users\\romain.ribault\\Documents\\GitHub\\torchydra           \n",
      "│       data_dir: C:\\Users\\romain.ribault\\Documents\\GitHub\\torchydra/data/     \n",
      "│       log_dir: C:\\Users\\romain.ribault\\Documents\\GitHub\\torchydra/outputs/   \n",
      "│       output_dir: c:\\Users\\romain.ribault\\Documents\\GitHub\\torchydra\\outputs\\\n",
      "│       work_dir: c:\\Users\\romain.ribault\\Documents\\GitHub\\torchydra           \n",
      "│       dataset: C:\\Users\\romain.ribault\\Documents\\GitHub\\torchydra/data//netcd\n",
      "│       training_env_dataset: c:\\Users\\romain.ribault\\Documents\\GitHub\\torchydr\n",
      "│                                                                              \n",
      "├── extras\n",
      "│   └── ignore_warnings: false                                                 \n",
      "│       enforce_tags: true                                                     \n",
      "│       print_config: true                                                     \n",
      "│                                                                              \n",
      "├── task_name\n",
      "│   └── eval                                                                   \n",
      "├── tags\n",
      "│   └── ['dev']                                                                \n",
      "├── experiment_folder\n",
      "│   └── outputs/tutorial/runs/2023-05-15_11-38-05                              \n",
      "├── save_path\n",
      "│   └── \\\\10.12.89.104\\zefyros_calc\\PreProd\\storage                            \n",
      "└── date\n",
      "    └── 2022-12-02                                                             \n",
      "c:\\Users\\romain.ribault\\Anaconda3\\envs\\dmltp\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator MinMaxScaler from version 1.2.2 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\romain.ribault\\Anaconda3\\envs\\dmltp\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator PCA from version 1.2.2 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\romain.ribault\\Anaconda3\\envs\\dmltp\\lib\\site-packages\\torchinfo\\torchinfo.py:477: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  action_fn=lambda data: sys.getsizeof(data.storage()),\n",
      "c:\\Users\\romain.ribault\\Anaconda3\\envs\\dmltp\\lib\\site-packages\\torch\\storage.py:665: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return super().__sizeof__() + self.nbytes()\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "conv1d_surr                              [1, 24, 18]               --\n",
      "├─Linear: 1-1                            [64]                      512\n",
      "├─ReLU: 1-2                              [64]                      --\n",
      "├─Linear: 1-3                            [32]                      2,080\n",
      "├─ReLU: 1-4                              [32]                      --\n",
      "├─ConvTranspose1d: 1-5                   [1, 64, 64]               131,136\n",
      "├─ReLU: 1-6                              [1, 64, 64]               --\n",
      "├─ConvTranspose1d: 1-7                   [1, 128, 128]             16,512\n",
      "├─ReLU: 1-8                              [1, 128, 128]             --\n",
      "├─ConvTranspose1d: 1-9                   [1, 256, 256]             65,792\n",
      "├─ReLU: 1-10                             [1, 256, 256]             --\n",
      "├─ConvTranspose1d: 1-11                  [1, 512, 512]             262,656\n",
      "├─ReLU: 1-12                             [1, 512, 512]             --\n",
      "├─Conv1d: 1-13                           [1, 256, 256]             262,400\n",
      "├─ReLU: 1-14                             [1, 256, 256]             --\n",
      "├─Conv1d: 1-15                           [1, 128, 128]             65,664\n",
      "├─ReLU: 1-16                             [1, 128, 128]             --\n",
      "├─Conv1d: 1-17                           [1, 64, 64]               16,448\n",
      "├─ReLU: 1-18                             [1, 64, 64]               --\n",
      "├─Conv1d: 1-19                           [1, 18, 24]               20,754\n",
      "├─ReLU: 1-20                             [1, 18, 24]               --\n",
      "==========================================================================================\n",
      "Total params: 843,954\n",
      "Trainable params: 843,954\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 239.06\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 3.48\n",
      "Params size (MB): 3.38\n",
      "Estimated Total Size (MB): 6.85\n",
      "==========================================================================================\n",
      "c:\\Users\\romain.ribault\\Anaconda3\\envs\\dmltp\\lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:197: UserWarning: Attribute 'net' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['net'])`.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\romain.ribault\\Anaconda3\\envs\\dmltp\\lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:197: UserWarning: Attribute 'criterion' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['criterion'])`.\n",
      "  rank_zero_warn(\n",
      "[2023-05-16 09:54:55,923][eval][INFO] - ###\n",
      "[2023-05-16 09:54:55,923][eval][INFO] - get cos and sin decomposition of the data {'mag10': 'theta10', 'hs': 'dp'}\n",
      "[2023-05-16 09:54:55,923][eval][INFO] - get cos and sin decomposition of the data mag10 and theta10\n",
      "[2023-05-16 09:54:55,930][eval][INFO] - get cos and sin decomposition of the data hs and dp\n",
      "[2023-05-16 09:54:55,938][eval][INFO] - # input_envir_set shape is (24, 7)\n",
      "[2023-05-16 09:54:55,938][eval][INFO] - Perform model predictions\n",
      "[2023-05-16 09:54:56,088][eval][INFO] - uncertainty propagation and calculate 95% confidence interval based on input uncertainties\n",
      "[2023-05-16 09:55:07,298][eval][INFO] - Save netcdf file\n",
      "[2023-05-16 09:55:09,088][eval][INFO] - file saved in \\\\10.12.89.104\\zefyros_calc\\PreProd\\storage/2022/12/02/ANN/surrogate_2023-05-15_11-38-05 \n",
      "[2023-05-16 09:55:09,093][utils.utils][INFO] - Output dir: c:\\Users\\romain.ribault\\Documents\\GitHub\\torchydra\\outputs\\eval\\runs\\2023-05-16_09-54-55\n"
     ]
    }
   ],
   "source": [
    "# Run second model trained\n",
    "command = [\"python\", \"src/surrogate_inference.py\", f\"experiment_folder=outputs/tutorial/runs/{last_two_folders[1]}\" ]\n",
    "notebook_subprocess(command)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dmltp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
